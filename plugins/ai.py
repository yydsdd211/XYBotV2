import base64
import imghdr
import io
import json
import tomllib
import traceback
from uuid import uuid4

import aiosqlite
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langgraph.graph import START, MessagesState, StateGraph
from loguru import logger
from openai import AsyncOpenAI
from pydantic import BaseModel, Field

from WechatAPI import WechatAPIClient
from database import BotDatabase
from utils.decorators import *
from utils.plugin_base import PluginBase


class GenerateImage(BaseModel):
    """Generate a image using AI. ç”¨AIç”Ÿæˆä¸€ä¸ªå›¾ç‰‡ã€‚"""
    prompt: str = Field(..., description="The prompt(or description) of image")


class Ai(PluginBase):
    description = "AIæ’ä»¶"
    author = "HenryXiaoYang"
    version = "1.0.0"

    def __init__(self):
        super().__init__()

        with open("plugins/all_in_one_config.toml", "rb") as f:
            plugin_config = tomllib.load(f)

        with open("main_config.toml", "rb") as f:
            main_config = tomllib.load(f)

        config = plugin_config["Ai"]
        openai_config = main_config["OpenAI"]

        # get all the command from other plugin
        self.other_command = []
        for plugin in plugin_config:
            if plugin != "Ai":
                self.other_command.extend(plugin_config[plugin].get("command", []))
        self.other_command.extend(
            ["åŠ ç§¯åˆ†", "å‡ç§¯åˆ†", "è®¾ç½®ç§¯åˆ†", "æ·»åŠ ç™½åå•", "ç§»é™¤ç™½åå•", "ç™½åå•åˆ—è¡¨", "å¤©æ°”", "äº”å­æ£‹", "äº”å­æ£‹åˆ›å»º",
             "äº”å­æ£‹é‚€è¯·", "é‚€è¯·äº”å­æ£‹", "æŽ¥å—", "åŠ å…¥", "ä¸‹æ£‹", "åŠ è½½æ’ä»¶", "åŠ è½½æ‰€æœ‰æ’ä»¶", "å¸è½½æ’ä»¶", "å¸è½½æ‰€æœ‰æ’ä»¶",
             "é‡è½½æ’ä»¶", "é‡è½½æ‰€æœ‰æ’ä»¶", "æ’ä»¶åˆ—è¡¨"])

        main_config = main_config["XYBot"]

        # è¯»å– [Ai] è®¾ç½®
        self.enable = config["enable"]

        self.ai_db_url = config["database-url"]

        self.enable_command = config["enable-command"]
        self.enable_at = config["enable-at"]
        self.enable_private = config["enable-private"]

        self.command = config["command"]

        # è¯»å– [Ai.MainModel] è®¾ç½®
        config = plugin_config["Ai"]["MainModel"]
        self.base_url = config["base-url"] if config["base-url"] else openai_config["base-url"]
        self.api_key = config["api-key"] if config["api-key"] else openai_config["api-key"]

        self.model_name = config["model-name"]

        self.text_input = config["text-input"]
        self.image_input = config["image-input"]
        self.image_formats = config["image-formats"]
        self.voice_input = config["voice-input"]

        if self.voice_input not in ["None", "Native", "NonNative"]:
            logger.error("AIæ’ä»¶è®¾ç½®é”™è¯¯ï¼švoice-input å¿…é¡»ä¸º None æˆ–è€… Native æˆ–è€… NonNative")

        self.text_output = config["text-output"]
        self.image_output = config["image-output"]
        self.voice_output = config["voice-output"]

        if self.voice_output not in ["None", "Native", "NonNative"]:
            logger.error("AIæ’ä»¶è®¾ç½®é”™è¯¯ï¼švoice-output å¿…é¡»ä¸º None æˆ–è€… Native æˆ–è€… NonNative")

        self.temperature = config["temperature"]
        self.max_history_messages = config["max-history-messages"]
        self.model_kwargs = config["model_kwargs"]

        self.prompt = config["prompt"]

        modalities = []
        if self.text_output:
            modalities.append("text")
        if self.image_output:
            modalities.append("image")
        if self.voice_output == "Native":
            modalities.append("audio")
            if not self.model_kwargs.get("audio", None):
                self.model_kwargs["audio"] = {}
            self.model_kwargs["audio"]["format"] = "wav"

        self.model_kwargs["modalities"] = modalities

        # è¯»å–[Ai.Point]è®¾ç½®
        config = plugin_config["Ai"]["Point"]
        self.point_mode = config["mode"]

        if self.point_mode not in ["None", "Together"]:
            logger.error("AIæ’ä»¶è®¾ç½®é”™è¯¯ï¼špoint-mode å¿…é¡»ä¸º None æˆ–è€… Together")

        self.together_price = config["price"]

        self.admin_ignore = config["admin-ignore"]
        self.whitelist_ignore = config["whitelist-ignore"]

        # è¯»å– [Ai.GenerateImage] è®¾ç½®
        config = plugin_config["Ai"]["GenerateImage"]
        self.image_base_url = config["base-url"] if config["base-url"] else openai_config["base-url"]
        self.image_api_key = config["api-key"] if config["api-key"] else openai_config["api-key"]
        self.image_model_name = config["model-name"]
        self.image_size = config["size"]
        self.image_additional_param = config["additional-param"]

        if self.image_output:
            self.prompt += config["add-prompt"]

        # è¯»å– [Ai.SpeechToText] è®¾ç½®
        config = plugin_config["Ai"]["SpeechToText"]
        self.speech2text_base_url = config["base-url"] if config["base-url"] else openai_config["base-url"]
        self.speech2text_api_key = config["api-key"] if config["api-key"] else openai_config["api-key"]
        self.speech2text_model_name = config["model-name"]

        # è¯»å– [Ai.TextToSpeech] è®¾ç½®
        config = plugin_config["Ai"]["TextToSpeech"]
        self.text2speech_base_url = config["base-url"] if config["base-url"] else openai_config["base-url"]
        self.text2speech_api_key = config["api-key"] if config["api-key"] else openai_config["api-key"]
        self.text2speech_model_name = config["model-name"]
        self.text2speech_voice = config["voice"]
        self.text2speech_speed = config["speed"]
        self.text2speech_additional_param = config["additional-param"]

        # è¯»å–ä¸»è®¾ç½®
        self.admins = main_config["admins"]

        # åˆå§‹åŒ–langchain
        self.llm = ChatOpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            model=self.model_name,
            temperature=self.temperature,
            model_kwargs=self.model_kwargs
        )

        # tool-call
        if self.image_output:
            tools = [GenerateImage]
            self.llm = self.llm.bind_tools(tools)

        # åˆå§‹åŒ–æœºå™¨äººæ•°æ®åº“
        self.db = BotDatabase()

        # å‡†å¤‡å¼‚æ­¥åˆå§‹åŒ–
        self.sqlite_conn = None
        self.sqlite_saver = None
        self.ai = None

        self.inited = False

    async def async_init(self):
        if not self.inited or self.sqlite_conn is None or self.sqlite_conn.closed:  # æ·»åŠ è¿žæŽ¥çŠ¶æ€æ£€æŸ¥
            if self.sqlite_conn and not self.sqlite_conn.closed:
                await self.sqlite_conn.close()

            self.sqlite_conn = await aiosqlite.connect(self.ai_db_url)
            self.sqlite_saver = AsyncSqliteSaver(self.sqlite_conn)

            workflow = StateGraph(state_schema=MessagesState)
            workflow.add_edge(START, "model")
            workflow.add_node("model", self.call_model)

            self.ai = workflow.compile(checkpointer=self.sqlite_saver)

            self.inited = True

            logger.info("AIæ’ä»¶æ•°æ®åº“åˆå§‹åŒ–å®Œæ¯•")

    def __del__(self):
        """ç¡®ä¿èµ„æºè¢«æ­£ç¡®é‡Šæ”¾"""
        try:
            if hasattr(self, 'sqlite_conn') and self.sqlite_conn and not self.sqlite_conn.closed:
                import asyncio
                asyncio.run(self.sqlite_conn.close())
        except Exception as e:
            logger.error(f"å…³é—­æ•°æ®åº“è¿žæŽ¥æ—¶å‡ºé”™: {str(e)}")

    async def call_model(self, state: MessagesState):
        """å¤„ç†æ‰€æœ‰ç±»åž‹çš„æ¶ˆæ¯"""
        messages = state["messages"]

        # é™åˆ¶åŽ†å²æ¶ˆæ¯æ•°é‡
        if len(messages) > self.max_history_messages:
            # ä¿ç•™ç³»ç»Ÿæç¤º(ç¬¬ä¸€æ¡)å’Œæœ€è¿‘çš„æ¶ˆæ¯
            messages = [messages[0]] + messages[-self.max_history_messages + 1:]
            state["messages"] = messages  # æ›´æ–°çŠ¶æ€ä¸­çš„æ¶ˆæ¯åˆ—è¡¨

        try:
            response = await self.llm.ainvoke(messages)
            return {"messages": response}
        except Exception as e:
            logger.error(f"æ¨¡åž‹è°ƒç”¨å‡ºé”™: {str(e)}")
            raise

    @on_text_message
    async def handle_text(self, bot: WechatAPIClient, message: dict):
        if not self.enable:
            return

        if not self.text_input:
            return

        await self.async_init()

        content = str(message["Content"]).strip()
        command = content.split(" ")

        is_command = command[0] in self.command and self.enable_command
        is_private = not message["IsGroup"] and self.enable_private
        if not is_command and not is_private:
            return
        elif command[0] in self.other_command:
            return

        for c in ["æ¸…é™¤åŽ†å²è®°å½•", "æ¸…é™¤è®°å½•", "æ¸…é™¤åŽ†å²", "æ¸…é™¤å¯¹è¯"]:
            if c in message["Content"]:
                return await self.delete_user_thread_id(bot, message)
        for c in ["æ¸…é™¤æ‰€æœ‰äººåŽ†å²è®°å½•", "æ¸…é™¤æ‰€æœ‰åŽ†å²è®°å½•", "æ¸…é™¤æ‰€æœ‰è®°å½•", "æ¸…é™¤æ‰€æœ‰äººè®°å½•", "æ¸…é™¤æ‰€æœ‰äººå¯¹è¯"]:
            if c in message["Content"]:
                if message["SenderWxid"] not in self.admins:
                    await bot.send_at_message(
                        message["FromWxid"],
                        f"\n-----XYBot-----\nðŸ˜ ä½ æ²¡æœ‰è¿™æ ·åšçš„æƒé™ï¼",
                        [message["SenderWxid"]]
                    )
                    return

                result = await self.delete_all_user_thread_id()
                if result:
                    await bot.send_at_message(
                        message["FromWxid"],
                        f"\n-----XYBot-----\nðŸ—‘ï¸æ¸…é™¤æˆåŠŸâœ…",
                        [message["SenderWxid"]]
                    )
                else:
                    await bot.send_at_message(
                        message["FromWxid"],
                        f"\n-----XYBot-----\næ¸…é™¤å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—",
                        [message["SenderWxid"]]
                    )

                return

        if message["IsGroup"]:
            message["Content"] = content[len(command[0]):].strip()

        if self.check_point(bot, message):
            await self.get_ai_response(bot, message)

    @on_at_message
    async def handle_at(self, bot: WechatAPIClient, message: dict):
        if not self.enable:
            return

        if not self.text_input:
            return

        await self.async_init()

        message["Content"] = str(message["Content"]).replace(f"@{bot.nickname}\u2005", "").strip()

        if self.check_point(bot, message):
            await self.get_ai_response(bot, message)

    @on_voice_message
    async def handle_voice(self, bot: WechatAPIClient, message: dict):
        if not self.enable:
            return

        if message["IsGroup"]:
            return

        if not self.voice_input:
            return

        await self.async_init()

        if self.check_point(bot, message):
            await self.get_ai_response(bot, message)

    @on_image_message
    async def handle_image(self, bot: WechatAPIClient, message: dict):
        if not self.enable:
            return

        if message["IsGroup"]:
            return

        if not self.image_input:
            return

        await self.async_init()

        if self.check_point(bot, message):
            await self.get_ai_response(bot, message)

    @schedule('cron', hour=5)
    async def reset_chat_history(self):
        await self.async_init()

        r = await self.delete_all_user_thread_id()
        if r:
            logger.success("æ•°æ®åº“ï¼šæ¸…é™¤AIä¸Šä¸‹æ–‡æˆåŠŸ")
        else:
            logger.error("æ•°æ®åº“ï¼šæ¸…é™¤AIä¸Šä¸‹æ–‡å¤±è´¥")

    async def get_ai_response(self, bot: WechatAPIClient, message: dict):
        from_wxid = message["FromWxid"]
        sender_wxid = message["SenderWxid"]
        user_input = message["Content"]

        if not user_input:
            await bot.send_at_message(from_wxid, "\n-----XYBot-----\nä½ è¿˜æ²¡è¾“å…¥å‘€ï¼ðŸ¤”", [sender_wxid])
            return

        try:
            # ä¸Šä¸‹æ–‡
            thread_id = self.db.get_llm_thread_id(sender_wxid, self.model_name)
            if not thread_id:
                thread_id = str(uuid4())
                self.db.save_llm_thread_id(sender_wxid, thread_id, self.model_name)
            configurable = {
                "configurable": {
                    "thread_id": thread_id,
                }
            }

            # æ¶ˆæ¯ç±»åž‹
            if message["MsgType"] == 1 and self.text_input:  # æ–‡æœ¬è¾“å…¥
                input_message = [
                    HumanMessage(content=self.prompt),
                    HumanMessage(content=user_input)
                ]

            elif message["MsgType"] == 3 and self.image_input:  # å›¾ç‰‡è¾“å…¥
                image_base64 = user_input

                image_format = self.get_img_format(image_base64)
                # æ£€æŸ¥å›¾ç‰‡æ ¼å¼
                if image_format not in self.image_formats:
                    await bot.send_at_message(
                        from_wxid,
                        f"-----XYBot-----\nâš ï¸ä¸æ”¯æŒè¯¥å›¾ç‰‡æ ¼å¼ï¼æ”¯æŒ: {self.image_formats}",
                        [sender_wxid]
                    )
                    return None
                input_message = [
                    HumanMessage(content=self.prompt),
                    HumanMessage(content=[
                        {"type": "image_url", "image_url": {"url": f"data:image/{image_format};base64,{image_base64}"}},
                    ])
                ]

            elif message["MsgType"] == 34 and self.voice_input != "None":  # è¯­éŸ³è¾“å…¥
                if self.voice_input == "Native":
                    wav_base64 = bot.byte_to_base64(user_input)
                    input_message = [
                        HumanMessage(content=self.prompt),
                        HumanMessage(content=[
                            {"type": "input_audio", "input_audio": {"data": wav_base64, "format": "wav"}},
                        ])
                    ]
                else:
                    text_input = await self.get_text_from_voice(user_input)
                    input_message = [
                        HumanMessage(content=self.prompt),
                        HumanMessage(content=text_input)
                    ]

            else:
                raise ValueError("æœªçŸ¥çš„è¾“å…¥æ ¼å¼ï¼")

            # è¯·æ±‚API
            logger.debug("è¯·æ±‚AIçš„API, thread id: {}", thread_id)
            output = await self.ai.ainvoke({"messages": input_message}, configurable)
            last_message = output["messages"][-1]

            # ä»€ä¹ˆç±»åž‹è¾“å…¥ï¼Œä»€ä¹ˆç±»åž‹è¾“å‡º
            if message["MsgType"] == 1 and self.text_output:  # æ–‡æœ¬è¾“å‡º
                if self.voice_output == "Native":
                    output = last_message.additional_kwargs['audio']['transcript']
                else:
                    output = last_message.content

                if output:
                    await bot.send_at_message(from_wxid, "\n" + output, [sender_wxid])

            elif message["MsgType"] == 3 and self.image_output:  # å›¾ç‰‡è¾“å‡º
                if self.voice_output == "Native":
                    output = last_message.additional_kwargs['audio']['transcript']
                else:
                    output = last_message.content

                if output:
                    await bot.send_at_message(from_wxid, "\n" + output, [sender_wxid])

            elif message["MsgType"] == 34 and self.voice_output != "None":  # è¯­éŸ³è¾“å‡º
                if self.voice_output == "Native":  # åŽŸç”Ÿæ”¯æŒ
                    if "audio" in last_message.additional_kwargs:
                        await bot.send_voice_message(from_wxid,
                                                     voice_base64=last_message.additional_kwargs['audio']['data'],
                                                     format="wav")
                    elif last_message.content:  # æ— è¯­éŸ³ï¼Œæœ‰æ–‡æœ¬
                        await bot.send_at_message(from_wxid, "\n" + last_message.content, [sender_wxid])
                else:  # éžåŽŸç”Ÿ
                    audio_byte = await self.get_voice_from_text(last_message.content)
                    audio_base64 = bot.byte_to_base64(audio_byte)
                    await bot.send_voice_message(from_wxid,
                                                 voice_base64=audio_base64,
                                                 format="wav")
            else:  # fallback
                await bot.send_at_message(from_wxid, "\n" + last_message.content, [sender_wxid])

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆtool call
            if last_message.additional_kwargs.get("tool_calls"):
                for tool_call in last_message.additional_kwargs["tool_calls"]:
                    if tool_call["function"]["name"] == "GenerateImage":
                        await bot.send_at_message(from_wxid, f"\nðŸ–¼ï¸æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...", [sender_wxid])
                        try:
                            prompt = json.loads(tool_call["function"]["arguments"])["prompt"]
                            img_b64 = await self.generate_image(prompt)
                            await bot.send_image_message(from_wxid, image_base64=img_b64)
                        except Exception as e:
                            logger.error(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {traceback.format_exc()}")
                            await bot.send_at_message(from_wxid, f"\nç”Ÿæˆå›¾ç‰‡å¤±è´¥: {str(e)}", [sender_wxid])

        except Exception as e:
            await bot.send_at_message(
                from_wxid,
                f"-----XYBot-----\nâŒè¯·æ±‚å¤±è´¥ï¼š{str(e)}",
                [sender_wxid]
            )
            logger.error(traceback.format_exc())

    async def generate_image(self, prompt: str) -> str:
        client = AsyncOpenAI(
            base_url=self.image_base_url,
            api_key=self.image_api_key
        )

        try:
            resp = await client.images.generate(
                model=self.image_model_name,
                prompt=prompt,
                size=self.image_size,
                n=1,
                response_format="b64_json",
                extra_body=self.image_additional_param
            )
            return resp.data[0].b64_json
        except:
            logger.error(traceback.format_exc())
            raise

    async def get_text_from_voice(self, user_input: bytes):
        tempfile = io.BytesIO(user_input)
        tempfile.name = "audio.wav"
        client = AsyncOpenAI(
            base_url=self.speech2text_base_url,
            api_key=self.speech2text_api_key
        )
        try:
            resp = await client.audio.transcriptions.create(
                model=self.speech2text_model_name,
                file=tempfile
            )
            return resp.text
        except:
            logger.error(traceback.format_exc())
            raise

    async def get_voice_from_text(self, text: str) -> bytes:
        client = AsyncOpenAI(
            base_url=self.text2speech_base_url,
            api_key=self.text2speech_api_key
        )
        try:
            resp = await client.audio.speech.create(
                model=self.text2speech_model_name,
                response_format="wav",
                voice=self.text2speech_voice,
                speed=float(self.text2speech_speed),
                # extra_body=self.text2speech_additional_param,
                input=text,
            )
            return resp.content
        except:
            logger.error(traceback.format_exc())
            raise

    @staticmethod
    def get_img_format(img_base64: str) -> str:
        if ',' in img_base64:
            img_base64 = img_base64.split(',')[1]
        return imghdr.what(io.BytesIO(base64.b64decode(img_base64)))  # Pythonç‰¹æœ‰çš„ç”¨å•è¡ŒåµŒå¥—æ¥åŠ é€Ÿæ€§èƒ½

    async def delete_user_thread_id(self, bot: WechatAPIClient, message: dict):
        thread_id_dict = dict(self.db.get_llm_thread_id(message["SenderWxid"]))
        cursor = await self.sqlite_conn.cursor()
        try:
            for value in thread_id_dict.values():
                cursor.execute("DELETE FROM checkpoints WHERE thread_id = ?", (value,))
                cursor.execute("DELETE FROM writes WHERE thread_id = ?", (value,))
            await self.sqlite_conn.commit()
        except Exception as e:
            await bot.send_at_message(
                message["FromWxid"],
                f"-----XYBot-----\nâŒåˆ é™¤å¤±è´¥ï¼š{str(e)}",
                [message["SenderWxid"]]
            )
            logger.error(traceback.format_exc())
            return
        finally:
            cursor.close()

        self.db.save_llm_thread_id(message["SenderWxid"], "", self.model_name)
        await bot.send_at_message(
            message["FromWxid"],
            f"\n-----XYBot-----\nðŸ—‘ï¸æ¸…é™¤æˆåŠŸâœ…",
            [message["SenderWxid"]]
        )
        return

    async def delete_all_user_thread_id(self) -> bool:
        logger.debug(self.db)
        self.db.delete_all_llm_thread_id()

        cursor = await self.sqlite_conn.cursor()
        try:
            await cursor.execute("DELETE FROM checkpoints")
            await cursor.execute("DELETE FROM writes")
            await self.sqlite_conn.commit()

            # å…³é—­å½“å‰è¿žæŽ¥
            await cursor.close()
            await self.sqlite_conn.close()

            # é‡æ–°å»ºç«‹è¿žæŽ¥å¹¶æ‰§è¡Œ VACUUM
            self.sqlite_conn = await aiosqlite.connect(self.ai_db_url)
            cursor = await self.sqlite_conn.cursor()
            await cursor.execute("VACUUM")

            # é‡æ–°åˆå§‹åŒ– sqlite_saver
            self.sqlite_saver = AsyncSqliteSaver(self.sqlite_conn)

        except Exception as e:
            logger.error(traceback.format_exc())
            return False
        finally:
            await cursor.close()

        return True

    async def check_point(self, bot: WechatAPIClient, message: dict) -> bool:
        wxid = message["SenderWxid"]

        if self.point_mode == "None":
            return True

        elif self.point_mode == "Together":
            if wxid in self.admins and self.admin_ignore:
                return True
            elif self.db.get_whitelist(wxid) and self.whitelist_ignore:
                return True
            else:
                if self.db.get_points(wxid) < self.together_price:
                    await bot.send_at_message(message["FromWxid"],
                                              f"\n-----XYBot-----\n"
                                              f"ðŸ˜­ä½ çš„ç§¯åˆ†ä¸å¤Ÿå•¦ï¼éœ€è¦ {self.together_price} ç§¯åˆ†",
                                              [wxid])
                    return False

                self.db.add_points(wxid, -self.together_price)
                return True

        else:
            return True
